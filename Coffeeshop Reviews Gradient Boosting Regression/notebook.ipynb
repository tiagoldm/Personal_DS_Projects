{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "866f2c66-beea-47eb-b714-65138b43b230",
   "metadata": {},
   "source": [
    "# Sample Exam: Coffee Shops\n",
    "\n",
    "Java June is a company that owns coffee shops in a number of locations in Europe.\n",
    "\n",
    "The company knows that stores with more reviews typically get more new customers. This is\n",
    "because new customers consider the number of reviews when picking between two shops.\n",
    "\n",
    "They want to get more insight into what leads to more reviews.\n",
    "\n",
    "They are also interested in whether there is a link between the number of reviews and rating.\n",
    "\n",
    "They want a report to answer these questions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a90b56-b27a-443e-ac6b-f296d97dc157",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "Before you start your analysis, you will need to make sure the data is clean. \n",
    "\n",
    "The table below shows what the data should look like. \n",
    "\n",
    "Create a cleaned version of the dataframe. \n",
    "\n",
    " - You should start with the data in the file \"coffee.csv\". \n",
    "\n",
    " - Your output should be a dataframe named `clean_data`. \n",
    "\n",
    " - All column names and values should match the table below.\n",
    "\n",
    "| Column Name | Criteria                                                |\n",
    "|-------------|---------------------------------------------------------|\n",
    "| Region    | Nominal. </br> Where the store is located. One of 10 possible regions (A to J).</br> Missing values should be replaced with “Unknown”.|\n",
    "| Place name | Nominal. </br>The name of the store. </br>Missing values should be replaced with “Unknown”.|\n",
    "| Place type  | Nominal. </br>The type of coffee shop. One of “Coffee shop”, “Cafe”, “Espresso bar”, and “Others”. </br>Missing values should be replaced with “Unknown”. |\n",
    "| Rating   | Ordinal. </br>Average rating of the store from reviews. On a 5 point scale. </br>Missing values should be replaced with 0. |\n",
    "| Reviews  | Nominal. </br>The number of reviews given to the store. </br>Missing values should be replaced with the overall median number.|\n",
    "| Price  | Ordinal. </br>The price range of products in the store. One of '\\$', '\\$\\$' or '\\$\\$\\$'. </br>Missing values should be replaced with ”Unknown”.|\n",
    "| Delivery Option   | Nominal. </br>If delivery is available. Either True or False. </br>Missing values should be replaced with False. |\n",
    "| Dine in Option | Nominal. </br>If dine in is available. Either True or False. </br>Missing values should be replaced with False. |\n",
    "| Takeaway Option | Nominal. </br>If take away is available. Either True or False. </br>Missing values should be replaced with False.|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af85dda8-59f8-4a21-80fc-02fa41224004",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 41,
    "lastExecutedAt": 1709245217349,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Importing relevant libraries and modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom category_encoders import OrdinalEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\n#Setting display settings\npd.set_option('display.max_columns', None)\n\n#Importing file with pd.read_csv\ncoffee = pd.read_csv(\"coffee.csv\")\n\n#Checking dtypes in columns\nprint(coffee.columns)\nprint(coffee.dtypes)\n\n#Checking unique values in columns\nunique_list=[]\nfor column in coffee.columns: \n    unique_list.append(coffee[column].unique())\nprint(unique_list)\n\n#Checking for missing values in the dataframe\nprint(coffee.isna().any())\n\n#Creating wrangler function\ndef wrangle(data):\n    \n    #Imputing missing values\n    coffee[\"Rating\"] = coffee[\"Rating\"].fillna(0)\n    coffee[\"Reviews\"] = coffee[\"Reviews\"].fillna(coffee[\"Reviews\"].median())\n    coffee[\"Dine in option\"] = coffee[\"Dine in option\"].fillna(False)\n    coffee[\"Takeout option\"] = coffee[\"Takeout option\"].fillna(False)\n    \n    #Correcting incorrect data types\n    coffee[\"Reviews\"] = coffee[\"Reviews\"].astype(str)\n    coffee[\"Delivery option\"] = coffee[\"Delivery option\"].astype(str)\n    coffee[\"Dine in option\"] = coffee[\"Dine in option\"].astype(str)\n    coffee[\"Takeout option\"] = coffee[\"Takeout option\"].astype(str)\n    \n    #Encoding categorical columns\n    label_encoder = OrdinalEncoder()\n    label_encoder.fit_transform(coffee[[\"Reviews\", \"Price\"]])\n\n    return coffee\n\n#Running wrangler\nclean_data = wrangle(coffee)\n\n#Checking clean_data\nprint(clean_data.head(10))\nprint(clean_data.dtypes)\nprint(clean_data.isna().any())",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['Region', 'Place name', 'Place type', 'Rating', 'Reviews', 'Price',\n",
      "       'Delivery option', 'Dine in option', 'Takeout option'],\n",
      "      dtype='object')\n",
      "Region              object\n",
      "Place name          object\n",
      "Place type          object\n",
      "Rating             float64\n",
      "Reviews            float64\n",
      "Price               object\n",
      "Delivery option       bool\n",
      "Dine in option      object\n",
      "Takeout option      object\n",
      "dtype: object\n",
      "[array(['C', 'J', 'F', 'B', 'A', 'E', 'D', 'G', 'I', 'H'], dtype=object), array(['Dim Kavu', 'Коферум', 'Кофейня Світ Чаю', 'Кофейня Starcoff',\n",
      "       'Кофейня \"Friend Zone\"', 'Racers Coffee Shop', 'Займемся Кофе',\n",
      "       'Кофейня Rit Rit', \"Кав'ярня My coffee\",\n",
      "       'LENЬ. Coffee & desserts.', 'SOVA COFFEE', 'Кава Тайм',\n",
      "       'Skver кафе', 'Кафе на Георгіївській', 'Khosper',\n",
      "       'Lekontina Шоколадна Майстерня', 'Lecker', 'Veterano Coffee',\n",
      "       'VEIN', 'Coffee Drive', 'G COFFEE', 'Kavun', 'Buns Brew Bar',\n",
      "       'Coffee House', '\"Точка кофе\"', 'Your Coffee', 'KOFEiN',\n",
      "       \"Perfect Coffee, КАВ'ЯРНЯ\", 'Misceva kavyarnya', 'Dzhi',\n",
      "       'Gangster coffee shop', 'Crema Caffe Poltava', 'COFFBOY',\n",
      "       'Wake Up Coffee', 'Lviv Handmade Chocolate',\n",
      "       'ПЕРША ДЕГУСТАЦІЙНА ЗАЛА КАВИ \"GANGSTER_COFFEE SHOP 3\"',\n",
      "       'Aroma kava', 'Koffishka', 'ЗАКУТОК - coffee hookah point',\n",
      "       'CoffeePot', 'Coffee 66', 'Godshot Coffee', 'Verona',\n",
      "       'Prostir.coffee Таврик', 'I love coffee', 'coffee House',\n",
      "       'Дом Кофе', 'CoffeeOk', 'Кофе с Совой', 'Кофе В Херсоне',\n",
      "       'Prostir.coffee', 'Don Marco coffee shop', 'HOTCUP', 'Koko',\n",
      "       'Coffee house', 'Coffeehouse Na Poshtovomu Provulku',\n",
      "       'Just Coffee Kherson', 'Don Marco', 'Green house', 'Kofemolka',\n",
      "       'Art Coffee', 'Art Coffee - Інтернет Магазин Кави та Чаю',\n",
      "       'Coffeeshop GRANO', 'Мастерская \"Кофе на разлив\"', 'Coffeeсть',\n",
      "       'The Boiler Room', 'Dim Kavy', 'Интернет-магазин \"Kava-e\"',\n",
      "       'Jays : Coffee Brewers', 'Caffisimo', 'MY COFFEE',\n",
      "       'Kaffe \"Na Peskah\"', 'LittleTalk Coffee', 'Столовая BUFET',\n",
      "       'Svit kavy', 'Comeback coffee & more', 'Coffeelab Roasters',\n",
      "       'Cholla & Joshua', 'Dobra Kava',\n",
      "       'Смажимо каву в Одесі. Обсмажувальна №2', 'Traveler`s Coffee',\n",
      "       'Кофе База Одесса | Coffee Baza', 'We Roast Coffee in Odessa',\n",
      "       'Burso_Coffee', 'Foundation Coffee Roasters',\n",
      "       'Red Cup Coffee Roasters', 'Krem Kafe', 'FAB.', 'Zheto',\n",
      "       'Eclair&Coffee', 'Coffee Room', 'Смажимо каву. Обсмажувальна N3',\n",
      "       'kofevarka.odessa.ua', 'Anso Coffee', 'Pasadena Coffee',\n",
      "       'Coffeetory Кофетория', 'Жарим Кофе в Одессе. Обжарочная №4',\n",
      "       'Coffee break ZAVIDA', 'Lviv Coffee Manufacture', 'Svit Kavy',\n",
      "       'Na bambetli', 'Golden Ducat', 'Lviv coffee manufacture (Valova)',\n",
      "       'SDV Coffee', 'Fixage', 'Lʹvivsʹka Manufaktura Kavy', 'Вірменка',\n",
      "       'Saturdays Coffee Цирк', 'Chekhovych', 'Svit Kavy (Rynok Sq.)',\n",
      "       'Cafe 1', 'Liberty', 'Lviv Croissants', 'Rondo Cafe',\n",
      "       'Karmel Coffee Shop', 'SV Кафе', 'I Feel Espresso Bar',\n",
      "       'I want coffee', 'Кофейня My Coffee', \"Hunter's yard\",\n",
      "       'Crema Caffe Кривий Ріг', 'Tea, Coffee Shop',\n",
      "       'Антикафе 7/9 | Кривой Рог', 'Чай Кофе', 'Coffee Craft',\n",
      "       'ЕТУАЛЬ КАФЕ', 'Coffee Break', 'Dva Gusya Pizza', 'Offshore cafe',\n",
      "       'Франс.уа на Пушкина', 'Дикий Койот кафе', 'BON BON',\n",
      "       'The Spiceroom', 'Магазин AROMA coffee&tea shop', 'coffeeok',\n",
      "       '\"®КАВА БАЗА®\"', 'Coffee in Action', 'Горький Espresso Bar',\n",
      "       'Кафе Бутик', 'Cuba Coffee Brew - Bar', 'Progress Cafe',\n",
      "       'Буду Кофе', 'ONE LOVE espresso bar', 'Matílda cafe',\n",
      "       'TAKAVA Coffee-Buffet', 'Kaffa', 'The Blue Cup Coffee Shop',\n",
      "       'LION coffee', 'London', 'PRO Coffee', 'RIGHT coffee bar',\n",
      "       'Espressoholic', 'Matin Desserts & Coffee',\n",
      "       'КофеТочка Харьков - интернет-магазин кофе и кофеоборудования',\n",
      "       'Sweeter', 'Workshop coffee', 'Мастерская Кофе', 'Kofeyin',\n",
      "       'Dom Kofe', 'Cats and coffee | Киці та кава',\n",
      "       'CoffeeDoor Brewbar & Coffeeshop', 'Dom Kofe, Mah.',\n",
      "       'Kava U Shafi', 'Coffeelaktika', 'Caffissimo, КОФЕЙНЯ',\n",
      "       'Coffeelaktika coffee studio', 'KOFEiN®', 'Mr. Bourbon',\n",
      "       'DoubleDecker Cake and Coffee', 'Бамбук', 'I feel city cafe',\n",
      "       'Coffee Secrets', 'Horizontal kaffee',\n",
      "       'Coffee&Cake, Game zone PS4', 'Zeffirino', 'Coffee Life',\n",
      "       'The sisters', '\"Франс.уа\" кофейня-пекарня', 'Tsikava Kava',\n",
      "       'Try Bobry', 'Pa-si-ju Кафе', 'Колибри', 'Artist', 'Dream Cafe',\n",
      "       'РУТА КАФЕ ПП КУЛІЧЕНКО К.І.', \"Ob'yektna Kava\",\n",
      "       'О...МАРАТ КАФЕ ПП ПОЛІСТЕП'], dtype=object), array(['Others', 'Cafe', 'Coffee shop', 'Espresso bar'], dtype=object), array([4.6, 5. , 4.4, 4.8, 4.9, 4.5, 4.2, 4.7, 4.3, 4.1, nan, 4. , 3.9]), array([2.0600e+02, 2.4000e+01, 1.1000e+01, 3.3100e+02, 1.2000e+01,\n",
      "       3.6700e+02, 2.0000e+02, 2.9200e+02, 3.1000e+01, 1.2500e+02,\n",
      "       1.1200e+02, 1.4000e+01, 1.8000e+01, 8.0600e+02, 6.0900e+02,\n",
      "       1.7200e+02, 2.3400e+02, 1.3600e+02, 1.6600e+02, 1.0000e+01,\n",
      "       1.5960e+03, 1.7850e+03, 4.5900e+02, 3.2900e+02, 5.6900e+02,\n",
      "       8.6000e+02, 1.2400e+02, 8.9800e+02, 1.1950e+03, 3.4700e+02,\n",
      "       1.7000e+01, 1.3760e+03, 3.7000e+01, 2.2600e+02, 7.1600e+02,\n",
      "       1.5000e+01, 7.2600e+02, 1.3450e+03, 2.6000e+01, 4.8500e+02,\n",
      "       2.7900e+02, 2.4100e+02, 4.6000e+01,        nan, 5.8700e+02,\n",
      "       5.9300e+02, 1.0300e+02, 1.2010e+03, 6.7000e+01, 2.7500e+02,\n",
      "       2.7000e+01, 3.0400e+02, 5.9800e+02, 9.7000e+01, 3.8000e+01,\n",
      "       9.8000e+01, 1.1800e+02, 1.2100e+02, 1.3200e+02, 1.6700e+02,\n",
      "       2.2300e+02, 3.4100e+02, 3.8500e+02, 4.1400e+02, 4.4000e+02,\n",
      "       4.8800e+02, 8.0700e+02, 8.3700e+02, 1.4820e+03, 1.6560e+03,\n",
      "       3.3500e+02, 2.7000e+03, 1.2200e+02, 2.1000e+01, 1.4150e+03,\n",
      "       6.4000e+01, 4.7000e+01, 2.1410e+03, 3.6000e+01, 2.0200e+02,\n",
      "       1.1300e+02, 1.1100e+02, 4.0000e+01, 3.9000e+01, 7.8900e+02,\n",
      "       1.5000e+02, 8.0000e+01, 1.7937e+04, 2.9310e+03, 2.0890e+03,\n",
      "       8.1300e+02, 1.5170e+03, 8.5800e+02, 7.0200e+02, 1.0200e+02,\n",
      "       7.7800e+02, 1.0090e+03, 2.8730e+03, 3.6300e+02, 1.1990e+03,\n",
      "       1.2840e+03, 1.5700e+03, 2.2360e+03, 1.5700e+02, 3.2100e+02,\n",
      "       9.9800e+02, 1.5090e+03, 6.9900e+02, 4.7900e+02, 4.5500e+02,\n",
      "       4.0100e+02, 1.9000e+02, 3.4200e+02, 3.2700e+02, 4.9000e+01,\n",
      "       7.4000e+02, 1.4390e+03, 9.4700e+02, 1.5600e+02, 1.1600e+02,\n",
      "       3.3000e+01, 1.8200e+03, 2.2000e+01, 3.7300e+02, 6.9300e+02,\n",
      "       2.8200e+02, 2.3190e+03, 1.7370e+03, 1.2810e+03, 1.9080e+03,\n",
      "       8.2400e+02, 1.6330e+03, 3.5000e+01, 5.1400e+02, 1.3000e+03,\n",
      "       1.1000e+02, 2.6800e+02, 6.4200e+02, 4.0000e+02, 4.0300e+02,\n",
      "       2.9140e+03, 9.6000e+01, 1.3940e+03, 5.1200e+02, 3.0000e+00,\n",
      "       1.8500e+02, 2.2200e+02, 2.8900e+02, 2.6100e+02, 1.7580e+03,\n",
      "       5.5100e+02, 2.3810e+03, 1.8900e+02, 1.5290e+03, 8.3000e+02,\n",
      "       1.7000e+02, 1.5500e+02, 9.0000e+00, 2.0130e+03, 1.0510e+03,\n",
      "       9.6300e+02, 6.4600e+02, 1.6000e+01, 5.9900e+02]), array(['$$', '$', '$$$'], dtype=object), array([False,  True]), array([nan, True], dtype=object), array([nan, True], dtype=object)]\n",
      "Region             False\n",
      "Place name         False\n",
      "Place type         False\n",
      "Rating              True\n",
      "Reviews             True\n",
      "Price              False\n",
      "Delivery option    False\n",
      "Dine in option      True\n",
      "Takeout option      True\n",
      "dtype: bool\n",
      "  Region                Place name    Place type  Rating Reviews Price  \\\n",
      "0      C                  Dim Kavu        Others     4.6   206.0    $$   \n",
      "1      C                   Коферум          Cafe     5.0    24.0    $$   \n",
      "2      C          Кофейня Світ Чаю   Coffee shop     5.0    11.0    $$   \n",
      "3      C          Кофейня Starcoff   Coffee shop     4.4   331.0    $$   \n",
      "4      C     Кофейня \"Friend Zone\"   Coffee shop     5.0    12.0    $$   \n",
      "5      C        Racers Coffee Shop  Espresso bar     4.6   367.0    $$   \n",
      "6      C             Займемся Кофе   Coffee shop     4.6   200.0    $$   \n",
      "7      C           Кофейня Rit Rit   Coffee shop     4.6   292.0    $$   \n",
      "8      C        Кав'ярня My coffee   Coffee shop     4.8    31.0    $$   \n",
      "9      C  LENЬ. Coffee & desserts.   Coffee shop     4.8   125.0    $$   \n",
      "\n",
      "  Delivery option Dine in option Takeout option  \n",
      "0           False          False          False  \n",
      "1           False          False           True  \n",
      "2           False          False           True  \n",
      "3           False           True           True  \n",
      "4           False           True           True  \n",
      "5           False           True           True  \n",
      "6           False           True           True  \n",
      "7           False          False           True  \n",
      "8           False           True           True  \n",
      "9            True           True           True  \n",
      "Region              object\n",
      "Place name          object\n",
      "Place type          object\n",
      "Rating             float64\n",
      "Reviews             object\n",
      "Price               object\n",
      "Delivery option     object\n",
      "Dine in option      object\n",
      "Takeout option      object\n",
      "dtype: object\n",
      "Region             False\n",
      "Place name         False\n",
      "Place type         False\n",
      "Rating             False\n",
      "Reviews            False\n",
      "Price              False\n",
      "Delivery option    False\n",
      "Dine in option     False\n",
      "Takeout option     False\n",
      "dtype: bool\n"
     ]
    }
   ],
   "source": [
    "#Importing relevant libraries and modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from category_encoders import OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Setting display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "#Importing file with pd.read_csv\n",
    "coffee = pd.read_csv(\"coffee.csv\")\n",
    "\n",
    "#Checking dtypes in columns\n",
    "print(coffee.columns)\n",
    "print(coffee.dtypes)\n",
    "\n",
    "#Checking unique values in columns\n",
    "unique_list=[]\n",
    "for column in coffee.columns: \n",
    "    unique_list.append(coffee[column].unique())\n",
    "print(unique_list)\n",
    "\n",
    "#Checking for missing values in the dataframe\n",
    "print(coffee.isna().any())\n",
    "\n",
    "#Creating wrangler function\n",
    "def wrangle(data):\n",
    "    \n",
    "    #Imputing missing values\n",
    "    coffee[\"Rating\"] = coffee[\"Rating\"].fillna(0)\n",
    "    coffee[\"Reviews\"] = coffee[\"Reviews\"].fillna(coffee[\"Reviews\"].median())\n",
    "    coffee[\"Dine in option\"] = coffee[\"Dine in option\"].fillna(False)\n",
    "    coffee[\"Takeout option\"] = coffee[\"Takeout option\"].fillna(False)\n",
    "    \n",
    "    #Correcting incorrect data types\n",
    "    coffee[\"Reviews\"] = coffee[\"Reviews\"].astype(str)\n",
    "    coffee[\"Delivery option\"] = coffee[\"Delivery option\"].astype(str)\n",
    "    coffee[\"Dine in option\"] = coffee[\"Dine in option\"].astype(str)\n",
    "    coffee[\"Takeout option\"] = coffee[\"Takeout option\"].astype(str)\n",
    "    \n",
    "    #Encoding categorical columns\n",
    "    label_encoder = OrdinalEncoder()\n",
    "    label_encoder.fit_transform(coffee[[\"Reviews\", \"Price\"]])\n",
    "\n",
    "    return coffee\n",
    "\n",
    "#Running wrangler\n",
    "clean_data = wrangle(coffee)\n",
    "\n",
    "#Checking clean_data\n",
    "print(clean_data.head(10))\n",
    "print(clean_data.dtypes)\n",
    "print(clean_data.isna().any())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed94a87e-8153-4778-a3d0-457c0dcb1c59",
   "metadata": {},
   "source": [
    "# Task 2 \n",
    "\n",
    "The team at Java June believe that the number of reviews changes depending on the rating. \n",
    "\n",
    "Producing a table showing the difference in the median number of reviews by rating along with the minimum and maximum number of reviews to investigate this question for the team.\n",
    "\n",
    " - You should start with the data in the file 'coffee.csv'.\n",
    "\n",
    " - Your output should be a data frame named `reviews_by_rating`. \n",
    "\n",
    " - It should include the three columns `rating`, `med_review`, `min_review`, `max_review`. \n",
    "\n",
    " - Your answers should be rounded to 1 decimal place.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5da1e42-ba3d-4076-808b-2caf060869e6",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1709245217400,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Building reviews_by_reting df with Reviews, and Rating columns\nreviews_by_rating = coffee[[\"Rating\", \"Reviews\"]]\n\n#Using groupby and agreggation to obtain median, min, and max values of Reviews for each unique rating\nreviews_by_rating = reviews_by_rating.groupby(\"Rating\").agg({\"Reviews\": [\"median\", \"min\", \"max\"]}).reset_index()\n\n#Setting column names according to requirements\nreviews_by_rating.columns = [\"rating\", \"med_review\", \"min_review\", \"max_review\"]\n\n#Setting rating as index\nreviews_by_rating.set_index(\"rating\", inplace=True)\n\n#Viewing df to ensure everything is ok\nprint(reviews_by_rating)",
    "outputsMetadata": {
     "0": {
      "height": 317,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        med_review min_review max_review\n",
      "rating                                  \n",
      "0.0          271.5      271.5      271.5\n",
      "3.9            9.5       10.0        9.0\n",
      "4.0          804.5     1439.0      170.0\n",
      "4.1          452.5      189.0      716.0\n",
      "4.2          497.0      385.0      609.0\n",
      "4.3          221.5      102.0      646.0\n",
      "4.4          536.0     1201.0      947.0\n",
      "4.5          688.0     1195.0      998.0\n",
      "4.6          693.0     1009.0      963.0\n",
      "4.7          400.0      112.0       97.0\n",
      "4.8          137.5       10.0       98.0\n",
      "4.9           40.0       10.0       64.0\n",
      "5.0           18.0       10.0      440.0\n"
     ]
    }
   ],
   "source": [
    "#Building reviews_by_reting df with Reviews, and Rating columns\n",
    "reviews_by_rating = coffee[[\"Rating\", \"Reviews\"]]\n",
    "\n",
    "#Using groupby and agreggation to obtain median, min, and max values of Reviews for each unique rating\n",
    "reviews_by_rating = reviews_by_rating.groupby(\"Rating\").agg({\"Reviews\": [\"median\", \"min\", \"max\"]}).reset_index()\n",
    "\n",
    "#Setting column names according to requirements\n",
    "reviews_by_rating.columns = [\"rating\", \"med_review\", \"min_review\", \"max_review\"]\n",
    "\n",
    "#Setting rating as index\n",
    "reviews_by_rating.set_index(\"rating\", inplace=True)\n",
    "\n",
    "#Viewing df to ensure everything is ok\n",
    "print(reviews_by_rating)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2039b04a-2898-4e1b-8bb3-feda4c419d40",
   "metadata": {},
   "source": [
    "# Task 3\n",
    "\n",
    "Fit a baseline model to predict the number of reviews a store will get.\n",
    "\n",
    " 1. Fit your model using the data contained in “train.csv” </br></br>\n",
    "\n",
    " 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `Place name` and `rating`. The rating column must be your predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7887703d-e165-4eff-b9a0-fc26878b0311",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 70,
    "lastExecutedAt": 1709245217470,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Importing training and validation data\ntrain = pd.read_csv(\"train.csv\")\nX_test = pd.read_csv(\"validation.csv\")\n\n#Checking training and validation datasets\nprint(train.head(10))\nprint(X_test.head(10))\n\n#Imputing missing values\ndef fill_na(ds):\n    ds[\"Rating\"] = ds[\"Rating\"].fillna(0)\n    if \"Reviews\" in ds.columns:\n        ds[\"Reviews\"] = ds[\"Reviews\"].fillna(ds[\"Reviews\"].median())\n    ds[\"Dine in option\"] = ds[\"Dine.in.option\"].fillna(False)\n    ds[\"Takeout option\"] = ds[\"Takeout.option\"].fillna(False) \n    \n    return ds\n\ntrain = fill_na(train)\nX_test = fill_na(X_test)\n\n#Separating features and target for training and testing\nX_train = train.drop([\"Reviews\", \"Place.name\"], axis=1)\nY_train = train[\"Reviews\"]\nplace_names = X_test[\"Place.name\"]\nX_test.drop(\"Place.name\", axis =1, inplace=True)\n\n#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\nohe_cols = [\"Region\", \"Place.type\"]\noe_cols = [\"Price\", \"Delivery.option\", \"Dine.in.option\", \"Takeout.option\"]\nnon_enc_columns = [\"Rating\"]\n\n#Encoding nominal variables\nencoder = ColumnTransformer(\n    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n\n#Building function to run k-fold cross validation to get MSE of baseline model, using training subset\ndef bs_mse(feats, target):\n    \n    #Encoding categorical variables\n    enc_feats = encoder.fit_transform(feats)\n    \n    #Initializaing LogReg\n    tr_model = LinearRegression()\n    \n    #Defining cross-validation parameters\n    cross_val = KFold(n_splits=5, shuffle=True)\n    \n    #Obtaining scores for different splits\n    scores = cross_val_score(tr_model, enc_feats, target, cv=cross_val, scoring='neg_mean_squared_error')\n    \n    #Extracting the mean MSE from the folds\n    return math.sqrt(-scores.mean()) \n\n#Building data pipeline for baseline model\npipeline = Pipeline([('encoder', encoder),('baseline', LinearRegression())\n])\n\n#Fitting the model to the training data\npipeline.fit(X_train, Y_train)\n\n#Predicting reviews using baseline model\npredictions = pipeline.predict(X_test)\n\nbase_result = pd.DataFrame({\"Place Name\": place_names, \"rating\": predictions})\n\nprint(base_result.head(20))\nprint(bs_mse(X_train, Y_train))",
    "outputsMetadata": {
     "0": {
      "height": 616,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Region                Place.name    Place.type  Rating  Reviews Price  \\\n",
      "0      C                  Dim Kavu        Others     4.6    206.0    $$   \n",
      "1      C          Кофейня Світ Чаю   Coffee shop     5.0     11.0    $$   \n",
      "2      C     Кофейня \"Friend Zone\"   Coffee shop     5.0     12.0    $$   \n",
      "3      C        Racers Coffee Shop  Espresso bar     4.6    367.0    $$   \n",
      "4      C             Займемся Кофе   Coffee shop     4.6    200.0    $$   \n",
      "5      C           Кофейня Rit Rit   Coffee shop     4.6    292.0    $$   \n",
      "6      C        Кав'ярня My coffee   Coffee shop     4.8     31.0    $$   \n",
      "7      C  LENЬ. Coffee & desserts.   Coffee shop     4.8    125.0    $$   \n",
      "8      C                Skver кафе          Cafe     4.9     18.0    $$   \n",
      "9      C     Кафе на Георгіївській          Cafe     4.5    806.0     $   \n",
      "\n",
      "   Delivery.option Dine.in.option Takeout.option  \n",
      "0            False            NaN            NaN  \n",
      "1            False            NaN           True  \n",
      "2            False           True           True  \n",
      "3            False           True           True  \n",
      "4            False           True           True  \n",
      "5            False            NaN           True  \n",
      "6            False           True           True  \n",
      "7             True           True           True  \n",
      "8            False           True           True  \n",
      "9            False           True           True  \n",
      "  Region        Place.name   Place.type  Rating Price  Delivery.option  \\\n",
      "0      C           Коферум         Cafe     5.0    $$            False   \n",
      "1      C  Кофейня Starcoff  Coffee shop     4.4    $$            False   \n",
      "2      C       SOVA COFFEE  Coffee shop     4.8    $$            False   \n",
      "3      C         Кава Тайм  Coffee shop     4.9    $$            False   \n",
      "4      J              Dzhi         Cafe     4.5    $$             True   \n",
      "5      J         Koffishka  Coffee shop     4.1    $$            False   \n",
      "6      F            Verona       Others     4.5    $$             True   \n",
      "7      F     I love coffee  Coffee shop     4.7    $$            False   \n",
      "8      F          Дом Кофе  Coffee shop     4.6    $$            False   \n",
      "9      F    Prostir.coffee  Coffee shop     4.7    $$             True   \n",
      "\n",
      "  Dine.in.option Takeout.option  \n",
      "0            NaN           True  \n",
      "1           True           True  \n",
      "2           True           True  \n",
      "3            NaN           True  \n",
      "4           True           True  \n",
      "5           True           True  \n",
      "6           True            NaN  \n",
      "7           True           True  \n",
      "8           True           True  \n",
      "9           True           True  \n",
      "                            Place Name       rating\n",
      "0                              Коферум  -700.096511\n",
      "1                     Кофейня Starcoff   330.816136\n",
      "2                          SOVA COFFEE   216.591312\n",
      "3                            Кава Тайм  -217.665907\n",
      "4                                 Dzhi  1315.183630\n",
      "5                            Koffishka   869.509971\n",
      "6                               Verona  1093.291379\n",
      "7                        I love coffee   472.697255\n",
      "8                             Дом Кофе   501.253461\n",
      "9                       Prostir.coffee  1486.470136\n",
      "10                              HOTCUP  -358.321950\n",
      "11                          Art Coffee    54.062829\n",
      "12         Мастерская \"Кофе на разлив\"  -288.522089\n",
      "13                            Dim Kavy    -3.049584\n",
      "14               Jays : Coffee Brewers    26.120751\n",
      "15                   LittleTalk Coffee   681.694917\n",
      "16                          Dobra Kava  1155.400208\n",
      "17           We Roast Coffee in Odessa   594.494514\n",
      "18             Red Cup Coffee Roasters  -404.278698\n",
      "19  Жарим Кофе в Одессе. Обжарочная №4   -40.180720\n",
      "1569.5903438465064\n"
     ]
    }
   ],
   "source": [
    "#Importing training and validation data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "X_test = pd.read_csv(\"validation.csv\")\n",
    "\n",
    "#Checking training and validation datasets\n",
    "print(train.head(10))\n",
    "print(X_test.head(10))\n",
    "\n",
    "#Imputing missing values\n",
    "def fill_na(ds):\n",
    "    ds[\"Rating\"] = ds[\"Rating\"].fillna(0)\n",
    "    if \"Reviews\" in ds.columns:\n",
    "        ds[\"Reviews\"] = ds[\"Reviews\"].fillna(ds[\"Reviews\"].median())\n",
    "    ds[\"Dine in option\"] = ds[\"Dine.in.option\"].fillna(False)\n",
    "    ds[\"Takeout option\"] = ds[\"Takeout.option\"].fillna(False) \n",
    "    \n",
    "    return ds\n",
    "\n",
    "train = fill_na(train)\n",
    "X_test = fill_na(X_test)\n",
    "\n",
    "#Separating features and target for training and testing\n",
    "X_train = train.drop([\"Reviews\", \"Place.name\"], axis=1)\n",
    "Y_train = train[\"Reviews\"]\n",
    "place_names = X_test[\"Place.name\"]\n",
    "X_test.drop(\"Place.name\", axis =1, inplace=True)\n",
    "\n",
    "#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\n",
    "ohe_cols = [\"Region\", \"Place.type\"]\n",
    "oe_cols = [\"Price\", \"Delivery.option\", \"Dine.in.option\", \"Takeout.option\"]\n",
    "non_enc_columns = [\"Rating\"]\n",
    "\n",
    "#Encoding nominal variables\n",
    "encoder = ColumnTransformer(\n",
    "    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n",
    "\n",
    "#Building function to run k-fold cross validation to get MSE of baseline model, using training subset\n",
    "def bs_mse(feats, target):\n",
    "    \n",
    "    #Encoding categorical variables\n",
    "    enc_feats = encoder.fit_transform(feats)\n",
    "    \n",
    "    #Initializaing LogReg\n",
    "    tr_model = LinearRegression()\n",
    "    \n",
    "    #Defining cross-validation parameters\n",
    "    cross_val = KFold(n_splits=5, shuffle=True)\n",
    "    \n",
    "    #Obtaining scores for different splits\n",
    "    scores = cross_val_score(tr_model, enc_feats, target, cv=cross_val, scoring='neg_mean_squared_error')\n",
    "    \n",
    "    #Extracting the mean MSE from the folds\n",
    "    return math.sqrt(-scores.mean()) \n",
    "\n",
    "#Building data pipeline for baseline model\n",
    "pipeline = Pipeline([('encoder', encoder),('baseline', LinearRegression())\n",
    "])\n",
    "\n",
    "#Fitting the model to the training data\n",
    "pipeline.fit(X_train, Y_train)\n",
    "\n",
    "#Predicting reviews using baseline model\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "base_result = pd.DataFrame({\"Place Name\": place_names, \"rating\": predictions})\n",
    "\n",
    "print(base_result.head(20))\n",
    "print(bs_mse(X_train, Y_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "024c3480-fe13-4ad3-8c8c-b6e808430de2",
   "metadata": {},
   "source": [
    "# Task 4\n",
    "\n",
    "Fit a comparison model to predict the number of reviews a store will get.\n",
    "\n",
    " 1. Fit your model using the data contained in “train.csv” </br></br>\n",
    "\n",
    " 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `Place name` and `rating`. The rating column must be your predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09a48881-fe15-4f2c-a40c-13874fa480dd",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 2503971,
    "lastExecutedAt": 1709247721441,
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "#Importing training and validation data\ntrain = pd.read_csv(\"train.csv\")\nX_test = pd.read_csv(\"validation.csv\")\n\n#Imputing missing values\ndef fill_na(ds):\n    ds[\"Rating\"] = ds[\"Rating\"].fillna(0)\n    if \"Reviews\" in ds.columns:\n        ds[\"Reviews\"] = ds[\"Reviews\"].fillna(ds[\"Reviews\"].median())\n    ds[\"Dine in option\"] = ds[\"Dine.in.option\"].fillna(False)\n    ds[\"Takeout option\"] = ds[\"Takeout.option\"].fillna(False) \n    \n    return ds\n\ntrain = fill_na(train)\nX_test = fill_na(X_test)\n\n#Separating features and target for training and testing\nX_train = train.drop([\"Reviews\", \"Place.name\"], axis=1)\ny_train = train[\"Reviews\"]\nplace_names = X_test[\"Place.name\"]\nX_test.drop(\"Place.name\", axis =1, inplace=True)\n\n#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\nohe_cols = [\"Region\", \"Place.type\"]\noe_cols = [\"Price\", \"Delivery.option\", \"Dine.in.option\", \"Takeout.option\"]\nnon_enc_columns = [\"Rating\"]\n\n#Encoding nominal variables\nencoder = ColumnTransformer(\n    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n\n#Creating mse_list to store mse's for different parameters, pred_list to store parameters\nmse_list=[]\nparam_list=[]\n\n#Building function to run k-fold cross validation to get MSE of Comparison model, using training subset\ndef cp_mse(feats, target):\n    \n    #Encoding categorical variables\n    enc_feats = encoder.fit_transform(feats)\n    \n    #Splitting train and test data within train dataset to assess performance\n    ft_train, ft_test, tg_train, tg_test = train_test_split(feats, target, test_size=0.75)\n    \n    #Iterating hyperparameters to find optimal combination\n    for max_depth in range(3, 10):\n       for n_estimators in range(50, 500):\n            for learning_rate in np.arange(0.01, 0.1, 0.01):\n                \n                #Initializing LogReg\n                tr_model = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n                \n                #Fitting the model to the training data\n                pipeline.fit(ft_train, tg_train)\n\n                #Predicting reviews using baseline model\n                y_pred = pipeline.predict(ft_test)\n                \n                #Appending parameters on param_list\n                param_list.append((n_estimators, max_depth, learning_rate))\n                \n                #Calculating MSE for each set of parameters\n                mse = mean_squared_error(tg_test, y_pred)\n                \n                #Appending mse values in mse_list\n                mse_list.append(math.sqrt(mse))\n                \n                #Finding parameters that provide the lowest mse\n                parameters = param_list[mse_list.index(min(mse_list))]\n                \n    return parameters, min(mse_list)\n\n#Defining the pipeline steps\npipeline = Pipeline([('encoder', encoder),('comparison', GradientBoostingRegressor(n_estimators=cp_mse(X_train, y_train)[0][0], max_depth=cp_mse(X_train, y_train)[0][1], learning_rate=cp_mse(X_train, y_train)[0][2]))])\n\n#Fitting the model to the training data\npipeline.fit(X_train, y_train)\n\n#Predicting reviews using baseline model\npredictions = pipeline.predict(X_test)\n\ncompare_result = pd.DataFrame({\"Place Name\": place_names, \"rating\": predictions})\nprint(cp_mse(X_train, Y_train))\nprint(compare_result.head(20))",
    "outputsMetadata": {
     "0": {
      "height": 457,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((50, 3, 0.01), 1134.0342313541917)\n",
      "                            Place Name      rating\n",
      "0                              Коферум  431.066828\n",
      "1                     Кофейня Starcoff  723.060917\n",
      "2                          SOVA COFFEE  500.625179\n",
      "3                            Кава Тайм  431.066828\n",
      "4                                 Dzhi  723.060917\n",
      "5                            Koffishka  723.060917\n",
      "6                               Verona  723.060917\n",
      "7                        I love coffee  668.592364\n",
      "8                             Дом Кофе  723.060917\n",
      "9                       Prostir.coffee  668.592364\n",
      "10                              HOTCUP  437.749661\n",
      "11                          Art Coffee  437.749661\n",
      "12         Мастерская \"Кофе на разлив\"  431.066828\n",
      "13                            Dim Kavy  435.544157\n",
      "14               Jays : Coffee Brewers  437.749661\n",
      "15                   LittleTalk Coffee  723.060917\n",
      "16                          Dobra Kava  723.060917\n",
      "17           We Roast Coffee in Odessa  723.060917\n",
      "18             Red Cup Coffee Roasters  431.066828\n",
      "19  Жарим Кофе в Одессе. Обжарочная №4  437.749661\n"
     ]
    }
   ],
   "source": [
    "#Importing training and validation data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "X_test = pd.read_csv(\"validation.csv\")\n",
    "\n",
    "#Imputing missing values\n",
    "def fill_na(ds):\n",
    "    ds[\"Rating\"] = ds[\"Rating\"].fillna(0)\n",
    "    if \"Reviews\" in ds.columns:\n",
    "        ds[\"Reviews\"] = ds[\"Reviews\"].fillna(ds[\"Reviews\"].median())\n",
    "    ds[\"Dine in option\"] = ds[\"Dine.in.option\"].fillna(False)\n",
    "    ds[\"Takeout option\"] = ds[\"Takeout.option\"].fillna(False) \n",
    "    \n",
    "    return ds\n",
    "\n",
    "train = fill_na(train)\n",
    "X_test = fill_na(X_test)\n",
    "\n",
    "#Separating features and target for training and testing\n",
    "X_train = train.drop([\"Reviews\", \"Place.name\"], axis=1)\n",
    "y_train = train[\"Reviews\"]\n",
    "place_names = X_test[\"Place.name\"]\n",
    "X_test.drop(\"Place.name\", axis =1, inplace=True)\n",
    "\n",
    "#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\n",
    "ohe_cols = [\"Region\", \"Place.type\"]\n",
    "oe_cols = [\"Price\", \"Delivery.option\", \"Dine.in.option\", \"Takeout.option\"]\n",
    "non_enc_columns = [\"Rating\"]\n",
    "\n",
    "#Encoding nominal variables\n",
    "encoder = ColumnTransformer(\n",
    "    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n",
    "\n",
    "#Building function to run k-fold cross validation to get MSE of Comparison model, using training subset\n",
    "def cp_mse(feats, target):\n",
    "    \n",
    "    #Creating mse_list to store mse's for different parameters, pred_list to store parameters\n",
    "    mse_list=[]\n",
    "    param_list=[]\n",
    "    \n",
    "    #Encoding categorical variables\n",
    "    enc_feats = encoder.fit_transform(feats)\n",
    "    \n",
    "    #Splitting train and test data within train dataset to assess performance\n",
    "    ft_train, ft_test, tg_train, tg_test = train_test_split(feats, target, test_size=0.75)\n",
    "    \n",
    "    #Iterating hyperparameters to find optimal combination\n",
    "    for max_depth in range(3, 10):\n",
    "       for n_estimators in range(50, 500):\n",
    "            for learning_rate in np.arange(0.01, 0.1, 0.01):\n",
    "                \n",
    "                #Initializing LogReg\n",
    "                tr_model = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n",
    "                \n",
    "                #Fitting the model to the training data\n",
    "                pipeline.fit(ft_train, tg_train)\n",
    "\n",
    "                #Predicting reviews using baseline model\n",
    "                y_pred = pipeline.predict(ft_test)\n",
    "                \n",
    "                #Appending parameters on param_list\n",
    "                param_list.append((n_estimators, max_depth, learning_rate))\n",
    "                \n",
    "                #Calculating MSE for each set of parameters\n",
    "                mse = mean_squared_error(tg_test, y_pred)\n",
    "                \n",
    "                #Appending mse values in mse_list\n",
    "                mse_list.append(math.sqrt(mse))\n",
    "                \n",
    "                #Finding parameters that provide the lowest mse\n",
    "                lowest_mse = mse_list.index(min(mse_list))\n",
    "                best_parameters = param_list[lowest_mse]\n",
    "                \n",
    "    return best_parameters, min(mse_list)\n",
    "\n",
    "#Defining the pipeline steps\n",
    "pipeline = Pipeline([('encoder', encoder),('comparison', GradientBoostingRegressor(n_estimators=cp_mse(X_train, y_train)[0][0], max_depth=cp_mse(X_train, y_train)[0][1], learning_rate=cp_mse(X_train, y_train)[0][2]))])\n",
    "\n",
    "#Fitting the model to the training data\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Predicting reviews using baseline model\n",
    "predictions = pipeline.predict(X_test)\n",
    "\n",
    "compare_result = pd.DataFrame({\"Place Name\": place_names, \"rating\": predictions})\n",
    "print(cp_mse(X_train, Y_train))\n",
    "print(compare_result.head(20))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
