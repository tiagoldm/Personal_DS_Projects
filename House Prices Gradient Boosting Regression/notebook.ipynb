{"cells":[{"source":"# Practical Exam: House sales\n\nRealAgents is a real estate company that focuses on selling houses.\n\nRealAgents sells a variety of types of house in one metropolitan area.\n\nSome houses sell slowly and sometimes require lowering the price in order to find a buyer.\n\nIn order to stay competitive, RealAgents would like to optimize the listing prices of the houses it is trying to sell.\n\nThey want to do this by predicting the sale price of a house given its characteristics.\n\nIf they can predict the sale price in advance, they can decrease the time to sale.\n\n\n## Data\n\nThe dataset contains records of previous houses sold in the area.\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n| house_id    | Nominal. </br> Unique identifier for houses. </br>Missing values not possible. |\n| city        | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton'. </br>Replace missing values with \"Unknown\". |\n| sale_price  | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries. |\n| sale_date   | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01. |\n| months_listed  | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n| bedrooms    | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer. |\n| house_type   | Ordinal. </br>One of \"Terraced\" (two shared walls), \"Semi-detached\" (one shared wall), or \"Detached\" (no shared walls). </br>Replace missing values with the most common house type. |\n| area      | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place. |\n","metadata":{},"id":"e33eda06-7d7d-445e-8cd0-60b4d4b13afb","cell_type":"markdown"},{"source":"# Task 1\n\nThe team at RealAgents knows that the city that a property is located in makes a difference to the sale price. \n\nUnfortuntately they believe that this isn't always recorded in the data. \n\nCalculate the number of missing values of the `city`. \n\n - You should use the data in the file \"house_sales.csv\". \n\n - Your output should be an object `missing_city`, that contains the number of missing values in this column. ","metadata":{},"id":"ce597564-6bd3-4f54-830b-d5bac083c04a","cell_type":"markdown"},{"source":"#Importing relevant libraries and modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.compose import ColumnTransformer\nfrom category_encoders import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\n#Setting display settings\npd.set_option('display.max_columns', None)\n\n#Importing file with pd.read_csv\nhouse_sales = pd.read_csv(\"house_sales.csv\")\n\n#Checking missing values in city\nprint(house_sales[\"city\"].value_counts())\n\n#Calculating missing/miscoded values in city\nmissing_city = (house_sales[\"city\"] == \"--\").sum()\n\n#Printing missing city to ensure it is correct\nprint(missing_city)","metadata":{"executionCancelledAt":null,"executionTime":18,"lastExecutedAt":1709400178672,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Importing relevant libraries and modules\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport math\nfrom sklearn.compose import ColumnTransformer\nfrom category_encoders import OrdinalEncoder\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import cross_val_score, KFold\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.model_selection import train_test_split\n\n#Setting display settings\npd.set_option('display.max_columns', None)\n\n#Importing file with pd.read_csv\nhouse_sales = pd.read_csv(\"house_sales.csv\")\n\n#Checking missing values in city\nprint(house_sales[\"city\"].value_counts())\n\n#Calculating missing/miscoded values in city\nmissing_city = (house_sales[\"city\"] == \"--\").sum()\n\n#Printing missing city to ensure it is correct\nprint(missing_city)","outputsMetadata":{"0":{"height":157,"type":"stream"}}},"id":"b2cb73bf-bb81-4664-b3eb-c35f6914a652","cell_type":"code","execution_count":167,"outputs":[{"output_type":"stream","name":"stdout","text":"Silvertown    517\nTeasdale      366\nPoppleton     362\nRiverford     182\n--             73\nName: city, dtype: int64\n73\n"}]},{"source":"# Task 2 \n\nBefore you fit any models, you will need to make sure the data is clean. \n\nThe table below shows what the data should look like. \n\nCreate a cleaned version of the dataframe. \n\n - You should start with the data in the file \"house_sales.csv\". \n\n - Your output should be a dataframe named `clean_data`. \n\n - All column names and values should match the table below.\n\n\n| Column Name | Criteria                                                |\n|-------------|---------------------------------------------------------|\n| house_id    | Nominal. </br> Unique identifier for houses. </br>Missing values not possible. |\n| city        | Nominal. </br>The city in which the house is located. One of 'Silvertown', 'Riverford', 'Teasdale' and 'Poppleton' </br>Replace missing values with \"Unknown\". |\n| sale_price  | Discrete. </br>The sale price of the house in whole dollars. Values can be any positive number greater than or equal to zero.</br>Remove missing entries. |\n| sale_date   | Discrete. </br>The date of the last sale of the house. </br>Replace missing values with 2023-01-01. |\n| months_listed  | Continuous. </br>The number of months the house was listed on the market prior to its last sale, rounded to one decimal place. </br>Replace missing values with mean number of months listed, to one decimal place. |\n| bedrooms    | Discrete. </br>The number of bedrooms in the house. Any positive values greater than or equal to zero. </br>Replace missing values with the mean number of bedrooms, rounded to the nearest integer. |\n| house_type   | Ordinal. </br>One of \"Terraced\", \"Semi-detached\", or \"Detached\". </br>Replace missing values with the most common house type. |\n| area      | Continuous. </br>The area of the house in square meters, rounded to one decimal place. </br>Replace missing values with the mean, to one decimal place. |","metadata":{},"id":"5045c039-b353-46ba-87b9-af63aaa4abf3","cell_type":"markdown"},{"source":"#Creating wrangler function\ndef wrangle(data):\n\n    #Correcting miscoded values\n    house_sales[\"city\"] = house_sales[\"city\"].apply(lambda x: \"Unknown\" if x==\"--\" else x)\n    house_sales[\"house_type\"] = house_sales[\"house_type\"].apply(lambda x: \"Terraced\" if x==\"Terr.\" else x)\n    house_sales[\"house_type\"] = house_sales[\"house_type\"].apply(lambda x: \"Semi-detached\" if x==\"Semi\" else x)\n    house_sales[\"house_type\"] = house_sales[\"house_type\"].apply(lambda x: \"Detached\" if x==\"Det.\" else x)\n    house_sales[\"area\"] = house_sales[\"area\"].apply(lambda x: x.split()[0])\n    \n    #Correcting incorrect data types\n    house_sales[\"house_id\"] = house_sales[\"house_id\"].astype(str)\n    house_sales[\"area\"] = house_sales[\"area\"].astype(float)\n    \n    #Imputing missing values\n    house_sales.dropna(subset=[\"sale_price\"], inplace=True)\n    house_sales[\"sale_date\"].fillna(\"2023-01-01\", inplace=True)\n    house_sales[\"months_listed\"].fillna(house_sales[\"months_listed\"].mean().round(1), inplace=True)\n    house_sales[\"bedrooms\"].fillna(house_sales[\"bedrooms\"].mean().round(0), inplace=True) \n    house_sales[\"area\"].fillna(house_sales[\"area\"].mean().round(1), inplace=True)\n    house_sales[\"house_type\"].fillna(house_sales[\"house_type\"].mode()[0], inplace=True)\n    \n    #Encoding nominal categorical columns \n    nominal_encoder = OneHotEncoder()\n    nominal_encoder.fit_transform(house_sales[[\"house_id\", \"city\"]])\n    \n    #Encoding ordinal categorical columns\n    label_encoder = OrdinalEncoder()\n    label_encoder.fit_transform(house_sales[[\"house_type\", \"sale_date\"]])\n\n    return house_sales\n\n#Running wrangler\nclean_data = wrangle(house_sales)\n\n#Checking every condition is met in clean_data\nprint(clean_data.head(10))\nprint(clean_data.dtypes)\nprint(clean_data.isna().any())\nprint((house_sales[\"sale_price\"] < 0).sum())","metadata":{"executionCancelledAt":null,"executionTime":60,"lastExecutedAt":1709400178732,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Creating wrangler function\ndef wrangle(data):\n\n    #Correcting miscoded values\n    house_sales[\"city\"] = house_sales[\"city\"].apply(lambda x: \"Unknown\" if x==\"--\" else x)\n    house_sales[\"house_type\"] = house_sales[\"house_type\"].apply(lambda x: \"Terraced\" if x==\"Terr.\" else x)\n    house_sales[\"house_type\"] = house_sales[\"house_type\"].apply(lambda x: \"Semi-detached\" if x==\"Semi\" else x)\n    house_sales[\"house_type\"] = house_sales[\"house_type\"].apply(lambda x: \"Detached\" if x==\"Det.\" else x)\n    house_sales[\"area\"] = house_sales[\"area\"].apply(lambda x: x.split()[0])\n    \n    #Correcting incorrect data types\n    house_sales[\"house_id\"] = house_sales[\"house_id\"].astype(str)\n    house_sales[\"area\"] = house_sales[\"area\"].astype(float)\n    \n    #Imputing missing values\n    house_sales.dropna(subset=[\"sale_price\"], inplace=True)\n    house_sales[\"sale_date\"].fillna(\"2023-01-01\", inplace=True)\n    house_sales[\"months_listed\"].fillna(house_sales[\"months_listed\"].mean().round(1), inplace=True)\n    house_sales[\"bedrooms\"].fillna(house_sales[\"bedrooms\"].mean().round(0), inplace=True) \n    house_sales[\"area\"].fillna(house_sales[\"area\"].mean().round(1), inplace=True)\n    house_sales[\"house_type\"].fillna(house_sales[\"house_type\"].mode()[0], inplace=True)\n    \n    #Encoding nominal categorical columns \n    nominal_encoder = OneHotEncoder()\n    nominal_encoder.fit_transform(house_sales[[\"house_id\", \"city\"]])\n    \n    #Encoding ordinal categorical columns\n    label_encoder = OrdinalEncoder()\n    label_encoder.fit_transform(house_sales[[\"house_type\", \"sale_date\"]])\n\n    return house_sales\n\n#Running wrangler\nclean_data = wrangle(house_sales)\n\n#Checking every condition is met in clean_data\nprint(clean_data.head(10))\nprint(clean_data.dtypes)\nprint(clean_data.isna().any())\nprint((house_sales[\"sale_price\"] < 0).sum())","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"dc9c2344-a350-461c-b5db-40768b2165a5","cell_type":"code","execution_count":168,"outputs":[{"output_type":"stream","name":"stdout","text":"  house_id        city  sale_price   sale_date  months_listed  bedrooms  \\\n0  1217792  Silvertown       55943  2021-09-12            5.4         2   \n1  1900913  Silvertown      384677  2021-01-17            6.3         5   \n2  1174927   Riverford      281707  2021-11-10            6.9         6   \n3  1773666  Silvertown      373251  2020-04-13            6.1         6   \n4  1258487  Silvertown      328885  2020-09-24            8.7         5   \n5  1539789   Riverford       47143  2020-09-25            5.1         2   \n6  1353069    Teasdale      429914  2021-05-18            5.9         6   \n7  1155864    Teasdale      284440  2020-10-15            5.8         4   \n8  1608726    Teasdale       87134  2021-01-07            4.4         2   \n9  1358764   Poppleton      211203  2020-05-04            3.0         4   \n\n      house_type   area  \n0  Semi-detached  107.8  \n1       Detached  498.8  \n2       Detached  542.5  \n3       Detached  528.4  \n4       Detached  477.1  \n5  Semi-detached  123.2  \n6       Detached  544.6  \n7       Detached  371.3  \n8  Semi-detached  125.7  \n9       Detached  371.5  \nhouse_id          object\ncity              object\nsale_price         int64\nsale_date         object\nmonths_listed    float64\nbedrooms           int64\nhouse_type        object\narea             float64\ndtype: object\nhouse_id         False\ncity             False\nsale_price       False\nsale_date        False\nmonths_listed    False\nbedrooms         False\nhouse_type       False\narea             False\ndtype: bool\n0\n"}]},{"source":"# Task 3 \n\nThe team at RealAgents have told you that they have always believed that the number of bedrooms is the biggest driver of house price. \n\nProducing a table showing the difference in the average sale price by number of bedrooms along with the variance to investigate this question for the team.\n\n - You should start with the data in the file 'house_sales.csv'.\n\n - Your output should be a data frame named `price_by_rooms`. \n\n - It should include the three columns `bedrooms`, `avg_price`, `var_price`. \n\n - Your answers should be rounded to 1 decimal place.   ","metadata":{},"id":"ff3c2889-66f3-4a6b-acac-2b12626e3244","cell_type":"markdown"},{"source":"#Building reviews_by_reting df with Reviews, and Rating columns\nprice_by_rooms = house_sales[[\"bedrooms\", \"sale_price\"]]\n\n#Using groupby and agreggation to obtain median, min, and max values of Reviews for each unique rating\nprice_by_rooms = price_by_rooms.groupby(\"bedrooms\").agg({\"sale_price\": [\"mean\", \"var\"]}).round(1).reset_index()\n\n#Setting column names according to requirements\nprice_by_rooms.columns = [\"bedrooms\", \"avg_price\", \"var_price\"]\n\n#Viewing df to ensure everything is ok\nprint(price_by_rooms)","metadata":{"executionCancelledAt":null,"executionTime":56,"lastExecutedAt":1709400178788,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Building reviews_by_reting df with Reviews, and Rating columns\nprice_by_rooms = house_sales[[\"bedrooms\", \"sale_price\"]]\n\n#Using groupby and agreggation to obtain median, min, and max values of Reviews for each unique rating\nprice_by_rooms = price_by_rooms.groupby(\"bedrooms\").agg({\"sale_price\": [\"mean\", \"var\"]}).round(1).reset_index()\n\n#Setting column names according to requirements\nprice_by_rooms.columns = [\"bedrooms\", \"avg_price\", \"var_price\"]\n\n#Viewing df to ensure everything is ok\nprint(price_by_rooms)","outputsMetadata":{"0":{"height":137,"type":"stream"}}},"id":"ea512a1c-e512-4f2e-8d78-323e51d01407","cell_type":"code","execution_count":169,"outputs":[{"output_type":"stream","name":"stdout","text":"   bedrooms  avg_price     var_price\n0         2    67076.4  5.652896e+08\n1         3   154665.1  2.378289e+09\n2         4   234704.6  1.725211e+09\n3         5   301515.9  2.484328e+09\n4         6   375741.3  3.924432e+09\n"}]},{"source":"# Task 4\n\nFit a baseline model to predict the sale price of a house.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `base_result`, that includes `house_id` and `price`. The price column must be your predicted values.","metadata":{},"id":"ac7038d1-7a8f-4d97-aef1-36f3f1227374","cell_type":"markdown"},{"source":"#Importing training and validation data\ntrain = pd.read_csv(\"train.csv\")\nX_test = pd.read_csv(\"validation.csv\")\n\n#Checking training and validation datasets\nprint(train.head(10))\nprint(X_test.head(10))\n\n#Checking datatypes of columns in both dataframes\nprint(train.dtypes)\nprint(X_test.dtypes)\n\n#Storing place names for later use\nhouse_ids = X_test[\"house_id\"]\n\n#Separating features and target for training and testing\nX_train = train.drop([\"house_id\", \"sale_price\"], axis=1)\ny_train = train[\"sale_price\"]\nX_test.drop(\"house_id\", axis =1, inplace=True)\n\n#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\nohe_cols = [\"city\"]\noe_cols = [\"sale_date\", \"house_type\"]\nnon_enc_columns = [\"months_listed\", \"bedrooms\", \"area\"]\n\n#Encoding nominal variables\nencoder = ColumnTransformer(\n    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n\n#Building function to run k-fold cross validation to get MSE of baseline model, using training subset\ndef bs_mse(feats, target):\n    \n    #Encoding categorical variables\n    enc_feats = encoder.fit_transform(feats)\n    \n    #Initializaing LogReg\n    tr_model = LinearRegression()\n    \n    #Defining cross-validation parameters\n    cross_val = KFold(n_splits=5, shuffle=True)\n    \n    #Obtaining scores for different splits\n    scores = cross_val_score(tr_model, enc_feats, target, cv=cross_val, scoring='neg_mean_squared_error')\n    \n    #Extracting the mean MSE from the folds\n    return math.sqrt(-scores.mean())\n\n#Building data pipeline for baseline model\npipeline = Pipeline([('encoder', encoder),('baseline', LinearRegression())\n])\n\n#Fitting the model to the training data\npipeline.fit(X_train, Y_train)\n\n#Predicting reviews using baseline model\npredictions = pipeline.predict(X_test)\n\nbase_result = pd.DataFrame({\"house_id\": house_ids, \"price\": predictions})\n\nprint(base_result.head(20))\nprint(bs_mse(X_train, y_train))","metadata":{"executionCancelledAt":null,"executionTime":65,"lastExecutedAt":1709400178853,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":"#Importing training and validation data\ntrain = pd.read_csv(\"train.csv\")\nX_test = pd.read_csv(\"validation.csv\")\n\n#Checking training and validation datasets\nprint(train.head(10))\nprint(X_test.head(10))\n\n#Checking datatypes of columns in both dataframes\nprint(train.dtypes)\nprint(X_test.dtypes)\n\n#Storing place names for later use\nhouse_ids = X_test[\"house_id\"]\n\n#Separating features and target for training and testing\nX_train = train.drop([\"house_id\", \"sale_price\"], axis=1)\ny_train = train[\"sale_price\"]\nX_test.drop(\"house_id\", axis =1, inplace=True)\n\n#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\nohe_cols = [\"city\"]\noe_cols = [\"sale_date\", \"house_type\"]\nnon_enc_columns = [\"months_listed\", \"bedrooms\", \"area\"]\n\n#Encoding nominal variables\nencoder = ColumnTransformer(\n    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n\n#Building function to run k-fold cross validation to get MSE of baseline model, using training subset\ndef bs_mse(feats, target):\n    \n    #Encoding categorical variables\n    enc_feats = encoder.fit_transform(feats)\n    \n    #Initializaing LogReg\n    tr_model = LinearRegression()\n    \n    #Defining cross-validation parameters\n    cross_val = KFold(n_splits=5, shuffle=True)\n    \n    #Obtaining scores for different splits\n    scores = cross_val_score(tr_model, enc_feats, target, cv=cross_val, scoring='neg_mean_squared_error')\n    \n    #Extracting the mean MSE from the folds\n    return math.sqrt(-scores.mean())\n\n#Building data pipeline for baseline model\npipeline = Pipeline([('encoder', encoder),('baseline', LinearRegression())\n])\n\n#Fitting the model to the training data\npipeline.fit(X_train, Y_train)\n\n#Predicting reviews using baseline model\npredictions = pipeline.predict(X_test)\n\nbase_result = pd.DataFrame({\"house_id\": house_ids, \"price\": predictions})\n\nprint(base_result.head(20))\nprint(bs_mse(X_train, y_train))","outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"96496c59-fdd4-4683-9884-551ad93b788f","cell_type":"code","execution_count":170,"outputs":[{"output_type":"stream","name":"stdout","text":"   house_id        city  sale_price   sale_date  months_listed  bedrooms  \\\n0   1634561    Teasdale      401869  2021-12-14            7.0         6   \n1   1009770  Silvertown      372387  2022-09-11            8.1         6   \n2   1946667  Silvertown      325473  2020-08-19            5.4         5   \n3   1798290  Silvertown      349469  2022-12-10            6.4         5   \n4   1533461   Poppleton      199995  2020-04-07            4.3         4   \n5   1232200    Teasdale       67372  2021-05-09            5.9         2   \n6   1182761   Poppleton      193803  2022-10-30            9.5         4   \n7   1346363   Poppleton      321844  2020-12-06            6.3         6   \n8   1459745   Riverford      268723  2022-09-07            5.8         6   \n9   1610313   Poppleton      113063  2021-07-19            2.2         3   \n\n      house_type   area  \n0       Detached  519.7  \n1       Detached  507.8  \n2       Detached  466.8  \n3       Detached  499.4  \n4       Detached  335.0  \n5  Semi-detached  116.5  \n6       Detached  321.8  \n7       Detached  582.9  \n8       Detached  553.0  \n9  Semi-detached  239.4  \n   house_id        city   sale_date  months_listed  bedrooms     house_type  \\\n0   1331375    Teasdale  2022-05-17            7.7         3       Terraced   \n1   1630115    Teasdale  2020-06-30            6.5         4       Detached   \n2   1645745  Silvertown  2020-09-02            7.4         6       Detached   \n3   1336775  Silvertown  2021-10-03            8.8         3  Semi-detached   \n4   1888274  Silvertown  2022-06-13            5.7         4       Detached   \n5   1567679    Teasdale  2022-08-10            4.9         4       Detached   \n6   1298770  Silvertown  2020-12-07            7.3         5       Detached   \n7   1662892   Riverford  2020-07-26            5.3         2  Semi-detached   \n8   1514321   Poppleton  2020-03-02            4.5         3       Detached   \n9   1795371  Silvertown  2022-05-10           10.5         3       Detached   \n\n    area  \n0  209.7  \n1  390.6  \n2  556.8  \n3  208.3  \n4  389.2  \n5  349.6  \n6  476.9  \n7  103.0  \n8  291.3  \n9  295.6  \nhouse_id           int64\ncity              object\nsale_price         int64\nsale_date         object\nmonths_listed    float64\nbedrooms           int64\nhouse_type        object\narea             float64\ndtype: object\nhouse_id           int64\ncity              object\nsale_date         object\nmonths_listed    float64\nbedrooms           int64\nhouse_type        object\narea             float64\ndtype: object\n    house_id          price\n0    1331375  122750.461406\n1    1630115  303458.806056\n2    1645745  385201.032573\n3    1336775  122155.867102\n4    1888274  271263.283228\n5    1567679  278775.385264\n6    1298770  330397.189577\n7    1662892  -15245.123913\n8    1514321  169874.401371\n9    1795371  210459.546256\n10   1872688  215947.899957\n11   1115697  143912.276838\n12   1752850  360471.738507\n13   1298746  350622.780577\n14   1464795  195744.234016\n15   1982802  168752.911245\n16   1823033  239844.251368\n17   1585193  142128.114874\n18   1843329  339319.670458\n19   1424530   36868.645864\n21880.117317467004\n"}]},{"source":"# Task 5\n\nFit a comparison model to predict the sale price of a house.\n\n 1. Fit your model using the data contained in “train.csv” </br></br>\n\n 2. Use “validation.csv” to predict new values based on your model. You must return a dataframe named `compare_result`, that includes `house_id` and `price`. The price column must be your predicted values.","metadata":{},"id":"7c674c01-d6de-488d-b2e0-bc3bbf87def6","cell_type":"markdown"},{"source":"#Importing training and validation data\ntrain = pd.read_csv(\"train.csv\")\nX_test = pd.read_csv(\"validation.csv\")\n\n#Checking training and validation datasets\nprint(train.head(10))\nprint(X_test.head(10))\n\n#Checking datatypes of columns in both dataframes\nprint(train.dtypes)\nprint(X_test.dtypes)\n\n#Storing place names for later use\nhouse_ids = X_test[\"house_id\"]\n\n#Separating features and target for training and testing\nX_train = train.drop([\"house_id\", \"sale_price\"], axis=1)\ny_train = train[\"sale_price\"]\nX_test.drop(\"house_id\", axis =1, inplace=True)\n\n#Columns to encode, split between ordinal encoding, non-ordinal encoding, and columns to passthrough\nohe_cols = [\"city\"]\noe_cols = [\"sale_date\", \"house_type\"]\nnon_enc_columns = [\"months_listed\", \"bedrooms\", \"area\"]\n\n#Encoding nominal variables\nencoder = ColumnTransformer(\n    transformers=[('ohe', OneHotEncoder(), ohe_cols), (\"oe\", OrdinalEncoder(), oe_cols), ('num', 'passthrough', non_enc_columns)])\n\n#Building function to run k-fold cross validation to get MSE of Comparison model, using training subset\ndef cp_mse(feats, target):\n    \n    #Creating mse_list to store mse's for different parameters, pred_list to store parameters\n    mse_list=[]\n    param_list=[]\n    \n    #Encoding categorical variables\n    enc_feats = encoder.fit_transform(feats)\n    \n    #Splitting train and test data within train dataset to assess performance\n    ft_train, ft_test, tg_train, tg_test = train_test_split(feats, target, test_size=0.75)\n    \n    #Iterating hyperparameters to find optimal combination\n    for max_depth in range(3, 6):\n       for n_estimators in range(50, 200):\n            for learning_rate in np.arange(0.01, 0.05, 0.01):\n                \n                #Initializing LogReg\n                tr_model = GradientBoostingRegressor(n_estimators=n_estimators, max_depth=max_depth, learning_rate=learning_rate)\n                \n                #Fitting the model to the training data\n                pipeline.fit(ft_train, tg_train)\n\n                #Predicting reviews using baseline model\n                y_pred = pipeline.predict(ft_test)\n                \n                #Appending parameters on param_list\n                param_list.append((n_estimators, max_depth, learning_rate))\n                \n                #Calculating MSE for each set of parameters\n                mse = mean_squared_error(tg_test, y_pred)\n                \n                #Appending mse values in mse_list\n                mse_list.append(math.sqrt(mse))\n                \n                #Finding parameters that provide the lowest mse\n                lowest_mse = mse_list.index(min(mse_list))\n                best_parameters = param_list[lowest_mse]\n                \n    return best_parameters, min(mse_list)\n\n#Storing function results to recurring function calls\nbest_parameters = cp_mse(X_train, y_train)[0]\nmin_mse = cp_mse(X_train, y_train)[1]\n\n#Defining the pipeline steps\npipeline = Pipeline([('encoder', encoder),('comparison', GradientBoostingRegressor(n_estimators=best_parameters[0], max_depth=best_parameters[1], learning_rate=best_parameters[2]))])\n\n#Fitting the model to the training data\npipeline.fit(X_train, y_train)\n\n#Predicting reviews using baseline model\npredictions = pipeline.predict(X_test)\n\ncompare_result = pd.DataFrame({\"house_id\": house_ids, \"price\": predictions})\nprint(best_parameters)\nprint(min_mse)\nprint(compare_result.head(20))","metadata":{"executionCancelledAt":null,"executionTime":null,"lastExecutedAt":null,"lastScheduledRunId":null,"lastSuccessfullyExecutedCode":null,"outputsMetadata":{"0":{"height":616,"type":"stream"}}},"id":"538ffb3d-4008-49b6-9876-7831e025f5a4","cell_type":"code","execution_count":148,"outputs":[{"output_type":"stream","name":"stdout","text":"   house_id        city  sale_price   sale_date  months_listed  bedrooms  \\\n0   1634561    Teasdale      401869  2021-12-14            7.0         6   \n1   1009770  Silvertown      372387  2022-09-11            8.1         6   \n2   1946667  Silvertown      325473  2020-08-19            5.4         5   \n3   1798290  Silvertown      349469  2022-12-10            6.4         5   \n4   1533461   Poppleton      199995  2020-04-07            4.3         4   \n5   1232200    Teasdale       67372  2021-05-09            5.9         2   \n6   1182761   Poppleton      193803  2022-10-30            9.5         4   \n7   1346363   Poppleton      321844  2020-12-06            6.3         6   \n8   1459745   Riverford      268723  2022-09-07            5.8         6   \n9   1610313   Poppleton      113063  2021-07-19            2.2         3   \n\n      house_type   area  \n0       Detached  519.7  \n1       Detached  507.8  \n2       Detached  466.8  \n3       Detached  499.4  \n4       Detached  335.0  \n5  Semi-detached  116.5  \n6       Detached  321.8  \n7       Detached  582.9  \n8       Detached  553.0  \n9  Semi-detached  239.4  \n   house_id        city   sale_date  months_listed  bedrooms     house_type  \\\n0   1331375    Teasdale  2022-05-17            7.7         3       Terraced   \n1   1630115    Teasdale  2020-06-30            6.5         4       Detached   \n2   1645745  Silvertown  2020-09-02            7.4         6       Detached   \n3   1336775  Silvertown  2021-10-03            8.8         3  Semi-detached   \n4   1888274  Silvertown  2022-06-13            5.7         4       Detached   \n5   1567679    Teasdale  2022-08-10            4.9         4       Detached   \n6   1298770  Silvertown  2020-12-07            7.3         5       Detached   \n7   1662892   Riverford  2020-07-26            5.3         2  Semi-detached   \n8   1514321   Poppleton  2020-03-02            4.5         3       Detached   \n9   1795371  Silvertown  2022-05-10           10.5         3       Detached   \n\n    area  \n0  209.7  \n1  390.6  \n2  556.8  \n3  208.3  \n4  389.2  \n5  349.6  \n6  476.9  \n7  103.0  \n8  291.3  \n9  295.6  \nhouse_id           int64\ncity              object\nsale_price         int64\nsale_date         object\nmonths_listed    float64\nbedrooms           int64\nhouse_type        object\narea             float64\ndtype: object\nhouse_id           int64\ncity              object\nsale_date         object\nmonths_listed    float64\nbedrooms           int64\nhouse_type        object\narea             float64\ndtype: object\n"}]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.8.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"editor":"DataCamp Workspace"},"nbformat":4,"nbformat_minor":5}